{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Users\\admin\\Documents\\NiDyN_EEGNET\\arl-eegmodels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EEGModels import EEGNet, ShallowConvNet, DeepConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "file_list = glob.glob(\"Processed_Data\\*norm.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "subj = 5\n",
    "\n",
    "for i in range(0,len(file_list)-1):\n",
    "    data = loadmat(file_list[i])\n",
    "    eeg_matrix = data['eeg_matrix_norm']\n",
    "    label_array = data['label_array']\n",
    "    labels = label_array.flatten()\n",
    "    label = np.zeros((len(label_array),2))\n",
    "    target_ind = labels == 1\n",
    "    label[target_ind,1] = 1\n",
    "    label[~target_ind,0] = 1\n",
    "    if i == 0:\n",
    "        eeg_matrix_train = eeg_matrix\n",
    "        label_train = label\n",
    "    elif i == subj:\n",
    "        eeg_matrix_test = eeg_matrix\n",
    "        label_test = label\n",
    "    else:\n",
    "        eeg_matrix_train = np.concatenate((eeg_matrix_train,eeg_matrix),axis=0)\n",
    "        label_train = np.concatenate((label_train,label),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_matrix_train = np.expand_dims(eeg_matrix_train,axis=1)\n",
    "eeg_matrix_test = np.expand_dims(eeg_matrix_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_windows = 10\n",
    "window_size = 151\n",
    "step_len = 10\n",
    "\n",
    "eeg_matrix_train_windowed = np.zeros((eeg_matrix_train.shape[0]*num_windows,1,eeg_matrix_train.shape[2],window_size))\n",
    "eeg_matrix_test_windowed = np.zeros((eeg_matrix_test.shape[0]*num_windows,1,eeg_matrix_test.shape[2],window_size))\n",
    "label_train_windowed = np.zeros((label_train.shape[0]*10,label_train.shape[1]))\n",
    "label_test_windowed = np.zeros((label_test.shape[0]*10,label_test.shape[1]))\n",
    "\n",
    "\n",
    "for trial in range(eeg_matrix_train.shape[0]):\n",
    "    for i in range(num_windows):\n",
    "        eeg_matrix_train_windowed[trial*num_windows+i,:,:,:] = eeg_matrix_train[trial,:,:,step_len*i:step_len*i+151]\n",
    "        \n",
    "for trial in range(eeg_matrix_test.shape[0]):\n",
    "    for i in range(num_windows):\n",
    "        eeg_matrix_test_windowed[trial*num_windows+i,:,:,:] = eeg_matrix_test[trial,:,:,step_len*i:step_len*i+151]\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "label_train_windowed[:,0] = np.repeat(label_train[:,0],10)\n",
    "label_train_windowed[:,1] = np.repeat(label_train[:,1],10)\n",
    "\n",
    "label_test_windowed[:,0] = np.repeat(label_test[:,0],10)\n",
    "label_test_windowed[:,1] = np.repeat(label_test[:,1],10)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16380, 2)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train_windowed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EEGNet(nb_classes = 2, Chans = 64, Samples = 151)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer=var_adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16380/16380 [==============================] - 12s 721us/step - loss: 0.9936 - acc: 0.5759\n",
      "Epoch 2/100\n",
      "16380/16380 [==============================] - 12s 717us/step - loss: 0.9908 - acc: 0.5740\n",
      "Epoch 3/100\n",
      "16380/16380 [==============================] - 12s 717us/step - loss: 0.9832 - acc: 0.5897\n",
      "Epoch 4/100\n",
      "16380/16380 [==============================] - 12s 718us/step - loss: 0.9790 - acc: 0.6010\n",
      "Epoch 5/100\n",
      "16380/16380 [==============================] - 12s 717us/step - loss: 0.9734 - acc: 0.6064\n",
      "Epoch 6/100\n",
      "16380/16380 [==============================] - 12s 718us/step - loss: 0.9710 - acc: 0.6046\n",
      "Epoch 7/100\n",
      "16380/16380 [==============================] - 12s 715us/step - loss: 0.9644 - acc: 0.6223\n",
      "Epoch 8/100\n",
      "16380/16380 [==============================] - 12s 715us/step - loss: 0.9601 - acc: 0.6239\n",
      "Epoch 9/100\n",
      "16380/16380 [==============================] - 12s 715us/step - loss: 0.9593 - acc: 0.6276\n",
      "Epoch 10/100\n",
      "16380/16380 [==============================] - 12s 716us/step - loss: 0.9574 - acc: 0.6307\n",
      "Epoch 11/100\n",
      "16380/16380 [==============================] - 12s 716us/step - loss: 0.9485 - acc: 0.6374\n",
      "Epoch 12/100\n",
      "16380/16380 [==============================] - 12s 715us/step - loss: 0.9457 - acc: 0.6477\n",
      "Epoch 13/100\n",
      "16380/16380 [==============================] - 12s 715us/step - loss: 0.9421 - acc: 0.6438\n",
      "Epoch 14/100\n",
      "16380/16380 [==============================] - 12s 715us/step - loss: 0.9366 - acc: 0.6501\n",
      "Epoch 15/100\n",
      "16380/16380 [==============================] - 12s 715us/step - loss: 0.9341 - acc: 0.6597\n",
      "Epoch 16/100\n",
      "16380/16380 [==============================] - 12s 714us/step - loss: 0.9306 - acc: 0.6604\n",
      "Epoch 17/100\n",
      "16380/16380 [==============================] - 12s 718us/step - loss: 0.9261 - acc: 0.6659\n",
      "Epoch 18/100\n",
      "16380/16380 [==============================] - 12s 717us/step - loss: 0.9190 - acc: 0.6712\n",
      "Epoch 19/100\n",
      "16380/16380 [==============================] - 12s 714us/step - loss: 0.9199 - acc: 0.6717\n",
      "Epoch 20/100\n",
      "16380/16380 [==============================] - 12s 714us/step - loss: 0.9163 - acc: 0.6726\n",
      "Epoch 21/100\n",
      "16380/16380 [==============================] - 12s 714us/step - loss: 0.9119 - acc: 0.6736\n",
      "Epoch 22/100\n",
      "16380/16380 [==============================] - 12s 717us/step - loss: 0.9086 - acc: 0.6790\n",
      "Epoch 23/100\n",
      "16380/16380 [==============================] - 12s 716us/step - loss: 0.9079 - acc: 0.6808\n",
      "Epoch 24/100\n",
      "16380/16380 [==============================] - 12s 716us/step - loss: 0.9076 - acc: 0.6788\n",
      "Epoch 25/100\n",
      "16380/16380 [==============================] - 12s 714us/step - loss: 0.9041 - acc: 0.6821\n",
      "Epoch 26/100\n",
      "16380/16380 [==============================] - 12s 715us/step - loss: 0.8980 - acc: 0.6872\n",
      "Epoch 27/100\n",
      "16380/16380 [==============================] - 12s 717us/step - loss: 0.8983 - acc: 0.6838\n",
      "Epoch 28/100\n",
      "16380/16380 [==============================] - 12s 721us/step - loss: 0.8938 - acc: 0.6899\n",
      "Epoch 29/100\n",
      "16380/16380 [==============================] - 12s 715us/step - loss: 0.8888 - acc: 0.6890\n",
      "Epoch 30/100\n",
      "16380/16380 [==============================] - 12s 717us/step - loss: 0.8899 - acc: 0.6892\n",
      "Epoch 31/100\n",
      "16380/16380 [==============================] - 12s 717us/step - loss: 0.8860 - acc: 0.6944\n",
      "Epoch 32/100\n",
      "16380/16380 [==============================] - 12s 714us/step - loss: 0.8821 - acc: 0.6952\n",
      "Epoch 33/100\n",
      "16380/16380 [==============================] - 12s 715us/step - loss: 0.8798 - acc: 0.6973\n",
      "Epoch 34/100\n",
      "16380/16380 [==============================] - 12s 719us/step - loss: 0.8792 - acc: 0.7012\n",
      "Epoch 35/100\n",
      "16380/16380 [==============================] - 12s 716us/step - loss: 0.8733 - acc: 0.7010\n",
      "Epoch 36/100\n",
      "16380/16380 [==============================] - 12s 717us/step - loss: 0.8752 - acc: 0.6990\n",
      "Epoch 37/100\n",
      "16380/16380 [==============================] - 12s 715us/step - loss: 0.8714 - acc: 0.7015\n",
      "Epoch 38/100\n",
      "16380/16380 [==============================] - 12s 717us/step - loss: 0.8675 - acc: 0.7034\n",
      "Epoch 39/100\n",
      "16380/16380 [==============================] - 12s 720us/step - loss: 0.8653 - acc: 0.7043\n",
      "Epoch 40/100\n",
      "16380/16380 [==============================] - 12s 718us/step - loss: 0.8624 - acc: 0.7043\n",
      "Epoch 41/100\n",
      "16380/16380 [==============================] - 12s 715us/step - loss: 0.8601 - acc: 0.7059\n",
      "Epoch 42/100\n",
      "16380/16380 [==============================] - 12s 717us/step - loss: 0.8502 - acc: 0.7103\n",
      "Epoch 43/100\n",
      "16380/16380 [==============================] - 12s 714us/step - loss: 0.8493 - acc: 0.7146\n",
      "Epoch 44/100\n",
      "16380/16380 [==============================] - 12s 718us/step - loss: 0.8543 - acc: 0.7083\n",
      "Epoch 45/100\n",
      "16380/16380 [==============================] - 12s 721us/step - loss: 0.8503 - acc: 0.7142\n",
      "Epoch 46/100\n",
      "16380/16380 [==============================] - 12s 714us/step - loss: 0.8523 - acc: 0.7139\n",
      "Epoch 47/100\n",
      "16380/16380 [==============================] - 12s 716us/step - loss: 0.8438 - acc: 0.7166\n",
      "Epoch 48/100\n",
      "16380/16380 [==============================] - 12s 714us/step - loss: 0.8467 - acc: 0.7145\n",
      "Epoch 49/100\n",
      "16380/16380 [==============================] - 12s 715us/step - loss: 0.8441 - acc: 0.7151\n",
      "Epoch 50/100\n",
      "16380/16380 [==============================] - 12s 718us/step - loss: 0.8403 - acc: 0.7140\n",
      "Epoch 51/100\n",
      "16380/16380 [==============================] - 12s 715us/step - loss: 0.8398 - acc: 0.7175\n",
      "Epoch 52/100\n",
      "16380/16380 [==============================] - 12s 713us/step - loss: 0.8382 - acc: 0.7228\n",
      "Epoch 53/100\n",
      "16380/16380 [==============================] - 12s 715us/step - loss: 0.8342 - acc: 0.7197\n",
      "Epoch 54/100\n",
      "16380/16380 [==============================] - 12s 715us/step - loss: 0.8351 - acc: 0.7248\n",
      "Epoch 55/100\n",
      "16380/16380 [==============================] - 12s 713us/step - loss: 0.8342 - acc: 0.7208\n",
      "Epoch 56/100\n",
      "16380/16380 [==============================] - 12s 718us/step - loss: 0.8282 - acc: 0.7273\n",
      "Epoch 57/100\n",
      "16380/16380 [==============================] - 12s 714us/step - loss: 0.8256 - acc: 0.7261\n",
      "Epoch 58/100\n",
      "16380/16380 [==============================] - 12s 715us/step - loss: 0.8261 - acc: 0.7241\n",
      "Epoch 59/100\n",
      "16380/16380 [==============================] - 12s 718us/step - loss: 0.8210 - acc: 0.7283\n",
      "Epoch 60/100\n",
      "16380/16380 [==============================] - 12s 716us/step - loss: 0.8171 - acc: 0.7284\n",
      "Epoch 61/100\n",
      "16380/16380 [==============================] - 12s 718us/step - loss: 0.8164 - acc: 0.7294\n",
      "Epoch 62/100\n",
      "16380/16380 [==============================] - 12s 717us/step - loss: 0.8129 - acc: 0.7352\n",
      "Epoch 63/100\n",
      "16380/16380 [==============================] - 12s 713us/step - loss: 0.8081 - acc: 0.7358\n",
      "Epoch 64/100\n",
      "16380/16380 [==============================] - 12s 713us/step - loss: 0.8116 - acc: 0.7319\n",
      "Epoch 65/100\n",
      "16380/16380 [==============================] - 12s 715us/step - loss: 0.8073 - acc: 0.7348\n",
      "Epoch 66/100\n",
      "16380/16380 [==============================] - 12s 720us/step - loss: 0.8055 - acc: 0.7369\n",
      "Epoch 67/100\n",
      "16380/16380 [==============================] - 12s 724us/step - loss: 0.8010 - acc: 0.7398\n",
      "Epoch 68/100\n",
      "16380/16380 [==============================] - 12s 715us/step - loss: 0.8030 - acc: 0.7367\n",
      "Epoch 69/100\n",
      "16380/16380 [==============================] - 12s 716us/step - loss: 0.8023 - acc: 0.7402\n",
      "Epoch 70/100\n",
      "16380/16380 [==============================] - 12s 714us/step - loss: 0.7931 - acc: 0.7405\n",
      "Epoch 71/100\n",
      "16380/16380 [==============================] - 12s 714us/step - loss: 0.7975 - acc: 0.7355\n",
      "Epoch 72/100\n",
      "16380/16380 [==============================] - 12s 714us/step - loss: 0.7895 - acc: 0.7451\n",
      "Epoch 73/100\n",
      "16380/16380 [==============================] - 12s 721us/step - loss: 0.7908 - acc: 0.7439\n",
      "Epoch 74/100\n",
      "16380/16380 [==============================] - 12s 714us/step - loss: 0.7880 - acc: 0.7411\n",
      "Epoch 75/100\n",
      "16380/16380 [==============================] - 12s 716us/step - loss: 0.7895 - acc: 0.7416\n",
      "Epoch 76/100\n",
      "16380/16380 [==============================] - 12s 715us/step - loss: 0.7858 - acc: 0.7457\n",
      "Epoch 77/100\n",
      "16380/16380 [==============================] - 12s 715us/step - loss: 0.7826 - acc: 0.7444\n",
      "Epoch 78/100\n",
      "16380/16380 [==============================] - 12s 722us/step - loss: 0.7795 - acc: 0.7500\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16380/16380 [==============================] - 12s 715us/step - loss: 0.7785 - acc: 0.7516\n",
      "Epoch 80/100\n",
      "16380/16380 [==============================] - 12s 715us/step - loss: 0.7773 - acc: 0.7460\n",
      "Epoch 81/100\n",
      "16380/16380 [==============================] - 12s 715us/step - loss: 0.7748 - acc: 0.7495\n",
      "Epoch 82/100\n",
      "16380/16380 [==============================] - 12s 714us/step - loss: 0.7730 - acc: 0.7462\n",
      "Epoch 83/100\n",
      "16380/16380 [==============================] - 12s 716us/step - loss: 0.7694 - acc: 0.7537\n",
      "Epoch 84/100\n",
      "16380/16380 [==============================] - 12s 724us/step - loss: 0.7747 - acc: 0.7505\n",
      "Epoch 85/100\n",
      "16380/16380 [==============================] - 12s 716us/step - loss: 0.7687 - acc: 0.7554\n",
      "Epoch 86/100\n",
      "16380/16380 [==============================] - 12s 715us/step - loss: 0.7712 - acc: 0.7512\n",
      "Epoch 87/100\n",
      "16380/16380 [==============================] - 12s 716us/step - loss: 0.7650 - acc: 0.7522\n",
      "Epoch 88/100\n",
      "16380/16380 [==============================] - 12s 716us/step - loss: 0.7672 - acc: 0.7542\n",
      "Epoch 89/100\n",
      "16380/16380 [==============================] - 12s 720us/step - loss: 0.7680 - acc: 0.7524\n",
      "Epoch 90/100\n",
      "16380/16380 [==============================] - 12s 718us/step - loss: 0.7653 - acc: 0.7524\n",
      "Epoch 91/100\n",
      "16380/16380 [==============================] - 12s 715us/step - loss: 0.7610 - acc: 0.7561\n",
      "Epoch 92/100\n",
      "16380/16380 [==============================] - 12s 715us/step - loss: 0.7536 - acc: 0.7549\n",
      "Epoch 93/100\n",
      "16380/16380 [==============================] - 12s 715us/step - loss: 0.7575 - acc: 0.7554\n",
      "Epoch 94/100\n",
      "16380/16380 [==============================] - 12s 713us/step - loss: 0.7529 - acc: 0.7570\n",
      "Epoch 95/100\n",
      "16380/16380 [==============================] - 12s 716us/step - loss: 0.7519 - acc: 0.7585\n",
      "Epoch 96/100\n",
      "16380/16380 [==============================] - 12s 715us/step - loss: 0.7564 - acc: 0.7572\n",
      "Epoch 97/100\n",
      "16380/16380 [==============================] - 12s 717us/step - loss: 0.7471 - acc: 0.7604\n",
      "Epoch 98/100\n",
      "16380/16380 [==============================] - 12s 715us/step - loss: 0.7450 - acc: 0.7621\n",
      "Epoch 99/100\n",
      "16380/16380 [==============================] - 12s 715us/step - loss: 0.7476 - acc: 0.7605\n",
      "Epoch 100/100\n",
      "16380/16380 [==============================] - 12s 715us/step - loss: 0.7506 - acc: 0.7607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x8d021518>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = {0:1, 1:3}\n",
    "model.fit(x = eeg_matrix_train_windowed, y = label_train_windowed, batch_size = 32, epochs = 100, class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model.predict(x = eeg_matrix_test_windowed, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.20462583, 0.7953742 ],\n",
       "       [0.26069796, 0.7393021 ],\n",
       "       [0.31974682, 0.68025315],\n",
       "       [0.4509282 , 0.5490718 ],\n",
       "       [0.5474253 , 0.45257467],\n",
       "       [0.58870935, 0.41129065],\n",
       "       [0.6737723 , 0.32622775],\n",
       "       [0.71982306, 0.28017688],\n",
       "       [0.7609662 , 0.23903379],\n",
       "       [0.76334965, 0.2366504 ],\n",
       "       [0.5654936 , 0.43450645],\n",
       "       [0.632364  , 0.36763597],\n",
       "       [0.7006799 , 0.29932004],\n",
       "       [0.723346  , 0.276654  ],\n",
       "       [0.7573081 , 0.24269187],\n",
       "       [0.7462949 , 0.25370505],\n",
       "       [0.7253163 , 0.27468365],\n",
       "       [0.71628   , 0.28372   ],\n",
       "       [0.74044746, 0.25955257],\n",
       "       [0.81813294, 0.1818671 ],\n",
       "       [0.7244938 , 0.27550617],\n",
       "       [0.7041489 , 0.2958511 ],\n",
       "       [0.6831366 , 0.31686342],\n",
       "       [0.6724413 , 0.32755864],\n",
       "       [0.65093267, 0.3490673 ],\n",
       "       [0.57436484, 0.42563513],\n",
       "       [0.5766474 , 0.4233526 ],\n",
       "       [0.6232875 , 0.37671253],\n",
       "       [0.66537195, 0.33462802],\n",
       "       [0.7233288 , 0.2766712 ],\n",
       "       [0.2836821 , 0.71631795],\n",
       "       [0.17241819, 0.8275818 ],\n",
       "       [0.2007626 , 0.79923743],\n",
       "       [0.16755018, 0.8324498 ],\n",
       "       [0.14295849, 0.8570415 ],\n",
       "       [0.15357052, 0.84642947],\n",
       "       [0.21751797, 0.782482  ],\n",
       "       [0.30539352, 0.6946065 ],\n",
       "       [0.3962022 , 0.6037978 ],\n",
       "       [0.5980641 , 0.4019359 ],\n",
       "       [0.6106651 , 0.38933492],\n",
       "       [0.50454724, 0.4954528 ],\n",
       "       [0.34372234, 0.65627766],\n",
       "       [0.2302526 , 0.76974744],\n",
       "       [0.22424707, 0.7757529 ],\n",
       "       [0.20740108, 0.79259884],\n",
       "       [0.26060104, 0.73939896],\n",
       "       [0.32961783, 0.6703822 ],\n",
       "       [0.28761306, 0.7123869 ],\n",
       "       [0.36524537, 0.6347546 ],\n",
       "       [0.8491606 , 0.15083937],\n",
       "       [0.84176296, 0.15823703],\n",
       "       [0.82193065, 0.1780693 ],\n",
       "       [0.8344143 , 0.16558574],\n",
       "       [0.7712142 , 0.22878581],\n",
       "       [0.73534405, 0.26465595],\n",
       "       [0.6894992 , 0.31050077],\n",
       "       [0.65294117, 0.3470589 ],\n",
       "       [0.75916964, 0.2408304 ],\n",
       "       [0.7990175 , 0.20098257],\n",
       "       [0.4007071 , 0.5992929 ],\n",
       "       [0.30701762, 0.6929823 ],\n",
       "       [0.34231994, 0.6576801 ],\n",
       "       [0.32484058, 0.6751594 ],\n",
       "       [0.3050649 , 0.6949351 ],\n",
       "       [0.38251883, 0.6174812 ],\n",
       "       [0.47162983, 0.52837014],\n",
       "       [0.5564809 , 0.44351912],\n",
       "       [0.59381074, 0.40618926],\n",
       "       [0.5533859 , 0.44661406],\n",
       "       [0.5800445 , 0.41995552],\n",
       "       [0.58388937, 0.41611066],\n",
       "       [0.6210814 , 0.37891862],\n",
       "       [0.68006694, 0.31993312],\n",
       "       [0.6577372 , 0.34226283],\n",
       "       [0.7305056 , 0.26949447],\n",
       "       [0.75773346, 0.24226649],\n",
       "       [0.77001053, 0.22998944],\n",
       "       [0.8238407 , 0.17615926],\n",
       "       [0.8499597 , 0.15004034],\n",
       "       [0.5828511 , 0.41714883],\n",
       "       [0.6964196 , 0.3035804 ],\n",
       "       [0.84077466, 0.15922537],\n",
       "       [0.9038972 , 0.09610278],\n",
       "       [0.9281961 , 0.07180393],\n",
       "       [0.947791  , 0.05220904],\n",
       "       [0.9472942 , 0.05270588],\n",
       "       [0.93832946, 0.06167051],\n",
       "       [0.931832  , 0.06816794],\n",
       "       [0.9331021 , 0.066898  ],\n",
       "       [0.79009837, 0.2099016 ],\n",
       "       [0.80247986, 0.19752005],\n",
       "       [0.8169833 , 0.18301669],\n",
       "       [0.79479414, 0.20520584],\n",
       "       [0.7720368 , 0.22796321],\n",
       "       [0.7596819 , 0.24031806],\n",
       "       [0.74706227, 0.25293773],\n",
       "       [0.66538537, 0.3346146 ],\n",
       "       [0.647259  , 0.352741  ],\n",
       "       [0.6505048 , 0.34949514]], dtype=float32)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[100:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325/325 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.55048073218419, 0.766153846337245]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x = eeg_matrix_test, y = label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-5b68ab331f87>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "model.weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
